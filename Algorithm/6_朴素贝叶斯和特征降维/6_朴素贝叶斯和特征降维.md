# 一、常见概率计算

朴素贝叶斯算法是利用**概率值进行分类**的一种机器学习算法

- 概率：一种事情发生的可能性，取值在[0,1]之间
  - 条件概率：表示事件A在另外一个事件B已经发生的条件下的发生概率$P(A|B)$
  - 联合概率：表示多个条件同时成立的概率$P(AB)=P(A)*P(B|A)=P(B)*P(A|B)$
  - 联合概率+条件概率
  - 相互独立：如果P(A,B)=P(A)P(B)，则称事件A与事件B相互独立

# 二、朴素贝叶斯算法

- 贝叶斯公式：$P(C|W)=\frac{P(W|C)P(C)}{P(W)}$
  - $P(C)$表示$C$出现的概率，一般是目标值
  - $P(W|C)$表示$C$条件下$W$出现的概率
  - $P(W)$表示W出现的概，$W$一般是特征
  
- 朴素贝叶斯在贝叶斯基础上增加：**特征条件独立假设**，即：特征之间是互为独立的，则$P(W_1,W_2|C)=P(W_1|C)*P(W_2|C)$

- 为了避免概率值为0（分母不能为0），我们需要在分子，分母分别加上一个数值，这就是**拉普拉斯平滑系数的作用**

  $P(F_1|C)=\frac{N_i+\alpha}{N+\alpha m}$

  - $\alpha$是拉普拉斯平滑系数，一般指定为1
  - $N_i$是$F_1$中符合条件$C$的样本数量
  - $N$是表示条件$C$下所有样本的总数
  - $m$表示所有独立样本的总数

## API

```python
sklearn.naive_bayes.MultinomialNB(alpha=1.0)
- 朴素贝叶斯分类
-alpha：拉普拉斯平滑系数
```

- 思路：使用jieba模块进行词频统计，然后进行机器学习

- 流程
  1. 获取数据
  2. 数据基本处理
     - 处理数据y
     - 加载停用词
     - 处理数据x把文档分词
     - 统计词频矩阵 作为句子特征
  3. 准备训练集测试集
  4. 模型训练
     - 实例化贝叶斯  台南佳拉普拉斯平滑系数
     - 模型预测
  5. 模型评估

# 三、特征降维

- 为什么要进行特征降维：特征对训练模型时是非常重要的，用于训练的数据集包含一些不重要的特征，可能导致模型泛化性能不佳
- 特征降维的目的：指在某些特定条件下，降低特征个数；目前阶段常用的方法是 低方差过滤法，PCA（主成分分析）降维法，相关系数（皮尔逊相关系数，斯皮尔曼相关系数）

## 1.低方差过滤法

- 概念：指的是删除方差低于某些阈值的一些特征
  - 特征方差小：特征值的波动范围小，包含的信息少，模型很难学习到信息
  - 特征方差大：特征值的波动范围大，包含的信息相对丰富，便于模型学习
- API

```python
sklearn.feature_seleciton.VarianceThreshold(threshold=0.0)
```

实例化对象用于删除所有低方差特征

```python
variance_obj.fit_transform(X)
```

X:numpy array格式的数据[n_samples,n_features]

- 返回值：训练集差异低于threshold的特征将会被删除（默认值是保留所有非零方差特征，即删除所有样本中具有相同值的特征）

## 2.主成分分析PCA

注意：在本身特征非常多的时候，不建议直接使用PCA进行处理，可以先使用低方差过滤法，过滤之后使用PCA进行处理

- 概念：PCA通过对**数据维数进行压缩**，尽可能降低原数据的维数（复杂度）损失少量信息，在此过程中可能会舍弃原有数据，创造新的变量

- API

  `sklearn.decomposition.PCA(n_components=None)`将数据分解为较低维数空间

  - n_components:小数表示**保留百分之多少**的信息；整数表示**减少到多少特征**
  - mypcaobj.fit_transform(X)
  - 返回值：转换后指定维度的array

## 3.相关系数

独立的两个变量一定是不相关的，不相关的两个变量不一定是独立的

### （1）基础

- 相关系数（$r$）：反应特征列之间（变量之间）密切相关程度的统计指标（两个变量之间的线性相关性）

- 常见的两个相关系数：皮尔逊相关系数，斯皮尔曼相关系数

- $-1 \leq r \leq +1$：当$r>0$时，表示两变量正相关，$r<0$时，两变量负相关；$|r|=1$表示两变量完全相关，$|r|=0$时表示两变量间无相关关系；$0<|r|<1$表示两变量存在一定程度的相关

  且$|r|$越接近于1，两变量间线性关系越密切；$|r|$越接近于0，表示两变量的线性关系相关越弱

- 一般可按三级划分：$|r|<0.4$为低度相关；$0.4 \leq r \leq 0.7$为显著性相关；$0.7\leq|r|<1$为高度线性相关

### （2）皮尔逊相关系数

​                                           $r=\frac{n\sum xy-\sum x\sum y}{\sqrt{n\sum x^2-(\sum x)^2}\sqrt{n\sum y^2-(\sum y)^2}}$

- API

```python
from scipy.stats import pearsonr
```

### （3）斯皮尔曼相关系数

​                                               $RankIC=1-\frac{6\sum d_i^2}{n(n^2-1)}$

- n为等级个数，d为成对变量的等级差数
- API

```python
from scipy.stats import spearmanr
```

